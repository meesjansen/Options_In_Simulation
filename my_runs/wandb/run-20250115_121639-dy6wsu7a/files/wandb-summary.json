{"global_step": 2500, "_timestamp": 1736940219.119405, "Reward / Instantaneous reward (max)": 51.290767669677734, "Reward / Instantaneous reward (min)": -110.48368835449219, "Reward / Instantaneous reward (mean)": -0.09337260574102402, "Reward / Total reward (max)": 116.91204833984375, "Reward / Total reward (min)": -141.84832763671875, "Reward / Total reward (mean)": 0.2616164982318878, "Episode / Total timesteps (max)": 299.0, "Episode / Total timesteps (min)": 89.0, "Episode / Total timesteps (mean)": 295.3477783203125, "_runtime": 420, "_step": 4, "Loss / Policy loss": -0.013859560713171959, "Loss / Value loss": 0.7227246165275574, "Loss / Entropy loss": -0.0425681546330452, "Policy / Standard deviation": 1.0, "Learning / Learning rate": 0.000750000006519258}