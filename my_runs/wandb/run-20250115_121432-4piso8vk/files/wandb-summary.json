{"global_step": 3000, "_timestamp": 1736940211.055948, "Reward / Instantaneous reward (max)": 528.9857177734375, "Reward / Instantaneous reward (min)": -282.1598815917969, "Reward / Instantaneous reward (mean)": 46.923030853271484, "Reward / Total reward (max)": 82754.0, "Reward / Total reward (min)": -55577.73828125, "Reward / Total reward (mean)": -2873.545166015625, "Episode / Total timesteps (max)": 299.0, "Episode / Total timesteps (min)": 34.0, "Episode / Total timesteps (mean)": 278.20098876953125, "_runtime": 539, "_step": 5, "Loss / Policy loss": -0.011070678941905499, "Loss / Value loss": 0.2816533148288727, "Loss / Entropy loss": -0.0425681546330452, "Policy / Standard deviation": 1.0, "Learning / Learning rate": 0.006666666828095913}