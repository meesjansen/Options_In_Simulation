{"global_step": 2500, "_timestamp": 1736940252.1184814, "Reward / Instantaneous reward (max)": 436.4601135253906, "Reward / Instantaneous reward (min)": -888.2555541992188, "Reward / Instantaneous reward (mean)": -0.3047885298728943, "Reward / Total reward (max)": 514.1072387695312, "Reward / Total reward (min)": -1379.017333984375, "Reward / Total reward (mean)": 63.044742584228516, "Episode / Total timesteps (max)": 299.0, "Episode / Total timesteps (min)": 19.0, "Episode / Total timesteps (mean)": 296.4350891113281, "_runtime": 452, "_step": 4, "Loss / Policy loss": -0.02048742026090622, "Loss / Value loss": 1.1332982778549194, "Loss / Entropy loss": -0.0425681546330452, "Policy / Standard deviation": 1.0, "Learning / Learning rate": 0.0005000000237487257}